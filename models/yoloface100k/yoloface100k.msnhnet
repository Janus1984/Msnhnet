config:
  batch: 1
  channels: 3
  width: 224
  height: 224
#0
conv:
  batchNorm: 1
  filters: 8
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#1
conv:
  batchNorm: 1
  filters: 8
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 8
  useBias: 1
  activation: relu
#2
conv:
  batchNorm: 1
  filters: 4
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#3
conv:
  batchNorm: 1
  filters: 18
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#4
conv:
  batchNorm: 1
  filters: 18
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 18
  useBias: 1
  activation: relu
#5
conv:
  batchNorm: 1
  filters: 6
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#6
conv:
  batchNorm: 1
  filters: 36
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#7
conv:
  batchNorm: 1
  filters: 36
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 36
  useBias: 1
  activation: relu
#8
conv:
  batchNorm: 1
  filters: 6
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#9
route:
  layers: -1,-4
  groups: 1
  groupsId: 0
  addModel: 1
  activation: none
#10
conv:
  batchNorm: 1
  filters: 18
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#11
route:
  layers: -8
  groups: 1
  groupsId: 0
  addModel: 0
  activation: none
#12
maxpool:
  kSizeX: 2
  kSizeY: 2
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
#13
route:
  layers: -1,10
  groups: 1
  groupsId: 0
  addModel: 0
  activation: none
#14
conv:
  batchNorm: 1
  filters: 24
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#15
conv:
  batchNorm: 1
  filters: 24
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 24
  useBias: 1
  activation: relu
#16
conv:
  batchNorm: 1
  filters: 8
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#17
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#18
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 40
  useBias: 1
  activation: relu
#19
conv:
  batchNorm: 1
  filters: 8
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#20
route:
  layers: -1,-4
  groups: 1
  groupsId: 0
  addModel: 1
  activation: none
#21
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#22
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 40
  useBias: 1
  activation: relu
#23
conv:
  batchNorm: 1
  filters: 8
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#24
route:
  layers: -1,-4
  groups: 1
  groupsId: 0
  addModel: 1
  activation: none
#25
conv:
  batchNorm: 1
  filters: 24
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#26
route:
  layers: -12
  groups: 1
  groupsId: 0
  addModel: 0
  activation: none
#27
maxpool:
  kSizeX: 2
  kSizeY: 2
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
#28
route:
  layers: -1,25
  groups: 1
  groupsId: 0
  addModel: 0
  activation: none
#29
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#30
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 2
  strideY: 2
  dilationX: 1
  dilationY: 1
  groups: 40
  useBias: 1
  activation: relu
#31
conv:
  batchNorm: 1
  filters: 16
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#32
conv:
  batchNorm: 1
  filters: 80
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#33
conv:
  batchNorm: 1
  filters: 80
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 80
  useBias: 1
  activation: relu
#34
conv:
  batchNorm: 1
  filters: 16
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#35
route:
  layers: -1,-4
  groups: 1
  groupsId: 0
  addModel: 1
  activation: none
#36
conv:
  batchNorm: 1
  filters: 80
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#37
conv:
  batchNorm: 1
  filters: 80
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 80
  useBias: 1
  activation: relu
#38
conv:
  batchNorm: 1
  filters: 16
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#39
route:
  layers: -1,-4
  groups: 1
  groupsId: 0
  addModel: 1
  activation: none
#40
conv:
  batchNorm: 1
  filters: 80
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#41
conv:
  batchNorm: 1
  filters: 80
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 80
  useBias: 1
  activation: relu
#42
conv:
  batchNorm: 1
  filters: 16
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#43
route:
  layers: -1,-4
  groups: 1
  groupsId: 0
  addModel: 1
  activation: none
#44
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#45
route:
  layers: -16
  groups: 1
  groupsId: 0
  addModel: 0
  activation: none
#46
maxpool:
  kSizeX: 2
  kSizeY: 2
  paddingX: 0
  paddingY: 0
  strideX: 2
  strideY: 2
#47
route:
  layers: -1,44
  groups: 1
  groupsId: 0
  addModel: 0
  activation: none
#48
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: relu
#49
conv:
  batchNorm: 1
  filters: 40
  kSizeX: 3
  kSizeY: 3
  paddingX: 1
  paddingY: 1
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 40
  useBias: 1
  activation: relu
#50
conv:
  batchNorm: 0
  filters: 18
  kSizeX: 1
  kSizeY: 1
  paddingX: 0
  paddingY: 0
  strideX: 1
  strideY: 1
  dilationX: 1
  dilationY: 1
  groups: 1
  useBias: 1
  activation: none
#51
yolo:
  anchors: 21, 28,  34, 49,  61, 77
  classNum: 1
#52
yoloout:
  layers: 51
  confThresh: 0.2
  nmsThresh: 0.2
  useSoftNms: 0
  yoloType: yolov3
